{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2341fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prasoon/Developer/MLOPS/YTintel-extension/venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as prasu202324\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as prasu202324\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"prasu202324/YTintel-extension\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"prasu202324/YTintel-extension\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository prasu202324/YTintel-extension initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository prasu202324/YTintel-extension initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 22:37:50 INFO mlflow.tracking.fluent: Experiment with name 'Exp 5 - ML Algos with HP Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1e723d12e289484281dcf8a904db21ce', creation_time=1771780071099, experiment_id='5', last_update_time=1771780071099, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}, workspace='default'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/prasu202324/YTintel-extension.mlflow\")\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner=\"prasu202324\", repo_name=\"YTintel-extension\", mlflow=True)\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44868e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923e7279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a904eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-22 23:07:39,091]\u001b[0m A new study created in memory with name: no-name-fa9d1e38-bb1b-4f86-bede-23e1625254ed\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:08:35,342]\u001b[0m Trial 0 finished with value: 0.7629892267830356 and parameters: {'n_estimators': 178, 'learning_rate': 0.04948570488678819, 'max_depth': 10}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:08:56,181]\u001b[0m Trial 1 finished with value: 0.600436383471976 and parameters: {'n_estimators': 87, 'learning_rate': 0.004590601593797585, 'max_depth': 7}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:09:52,287]\u001b[0m Trial 2 finished with value: 0.6136642574662484 and parameters: {'n_estimators': 136, 'learning_rate': 0.00010011087414229341, 'max_depth': 10}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:10:36,278]\u001b[0m Trial 3 finished with value: 0.6131187781262785 and parameters: {'n_estimators': 130, 'learning_rate': 0.0007342361840050876, 'max_depth': 9}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:10:43,306]\u001b[0m Trial 4 finished with value: 0.6791217782626483 and parameters: {'n_estimators': 155, 'learning_rate': 0.050045399057426054, 'max_depth': 3}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:11:13,839]\u001b[0m Trial 5 finished with value: 0.7467612164189281 and parameters: {'n_estimators': 174, 'learning_rate': 0.05734350839485382, 'max_depth': 7}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:11:50,920]\u001b[0m Trial 6 finished with value: 0.7198963589254057 and parameters: {'n_estimators': 191, 'learning_rate': 0.0339488135927062, 'max_depth': 7}. Best is trial 0 with value: 0.7629892267830356.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:12:21,911]\u001b[0m Trial 7 finished with value: 0.7902631937815355 and parameters: {'n_estimators': 255, 'learning_rate': 0.09727629975969848, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:14:28,837]\u001b[0m Trial 8 finished with value: 0.6352106913950634 and parameters: {'n_estimators': 297, 'learning_rate': 0.0010189487268850114, 'max_depth': 10}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:15:31,500]\u001b[0m Trial 9 finished with value: 0.6251193236056184 and parameters: {'n_estimators': 171, 'learning_rate': 0.00232653160366234, 'max_depth': 9}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:15:52,965]\u001b[0m Trial 10 finished with value: 0.6345288422201009 and parameters: {'n_estimators': 261, 'learning_rate': 0.00886556039746529, 'max_depth': 4}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:16:16,733]\u001b[0m Trial 11 finished with value: 0.7768989499522706 and parameters: {'n_estimators': 243, 'learning_rate': 0.09542361182811768, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:16:45,675]\u001b[0m Trial 12 finished with value: 0.6683485612982408 and parameters: {'n_estimators': 235, 'learning_rate': 0.015659208362993237, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:17:09,705]\u001b[0m Trial 13 finished with value: 0.7760807309423156 and parameters: {'n_estimators': 245, 'learning_rate': 0.09229044175136844, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:17:45,061]\u001b[0m Trial 14 finished with value: 0.7024410200463658 and parameters: {'n_estimators': 300, 'learning_rate': 0.02177458786058188, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:18:14,269]\u001b[0m Trial 15 finished with value: 0.7790808673121505 and parameters: {'n_estimators': 218, 'learning_rate': 0.09048865091863964, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:18:51,386]\u001b[0m Trial 16 finished with value: 0.6678030819582709 and parameters: {'n_estimators': 208, 'learning_rate': 0.014178809408751637, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:19:57,944]\u001b[0m Trial 17 finished with value: 0.6532115096140734 and parameters: {'n_estimators': 213, 'learning_rate': 0.006623025894529209, 'max_depth': 8}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:20:08,102]\u001b[0m Trial 18 finished with value: 0.558434474294286 and parameters: {'n_estimators': 55, 'learning_rate': 0.0001294661394732811, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:20:21,300]\u001b[0m Trial 19 finished with value: 0.5487522160098186 and parameters: {'n_estimators': 259, 'learning_rate': 0.0019986445841363256, 'max_depth': 3}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:21:12,337]\u001b[0m Trial 20 finished with value: 0.5587072139642711 and parameters: {'n_estimators': 277, 'learning_rate': 0.0002753982450989796, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:21:28,919]\u001b[0m Trial 21 finished with value: 0.7580799127233057 and parameters: {'n_estimators': 230, 'learning_rate': 0.09370997612037736, 'max_depth': 4}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:21:46,120]\u001b[0m Trial 22 finished with value: 0.6781671894177008 and parameters: {'n_estimators': 210, 'learning_rate': 0.026908123074766224, 'max_depth': 4}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:22:12,786]\u001b[0m Trial 23 finished with value: 0.779762716487113 and parameters: {'n_estimators': 267, 'learning_rate': 0.09236720461112653, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:22:54,350]\u001b[0m Trial 24 finished with value: 0.7456702577389881 and parameters: {'n_estimators': 278, 'learning_rate': 0.041572713080242255, 'max_depth': 6}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:24:16,104]\u001b[0m Trial 25 finished with value: 0.6844402018273558 and parameters: {'n_estimators': 267, 'learning_rate': 0.011302891704058552, 'max_depth': 8}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:24:43,786]\u001b[0m Trial 26 finished with value: 0.6836219828174008 and parameters: {'n_estimators': 222, 'learning_rate': 0.023053384006622407, 'max_depth': 5}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:25:36,484]\u001b[0m Trial 27 finished with value: 0.7858993590617755 and parameters: {'n_estimators': 249, 'learning_rate': 0.07037675567150586, 'max_depth': 8}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:26:38,577]\u001b[0m Trial 28 finished with value: 0.785490249556798 and parameters: {'n_estimators': 285, 'learning_rate': 0.06027024890756772, 'max_depth': 8}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "\u001b[32m[I 2026-02-22 23:27:45,558]\u001b[0m Trial 29 finished with value: 0.7749897722623755 and parameters: {'n_estimators': 285, 'learning_rate': 0.04960456698044434, 'max_depth': 8}. Best is trial 7 with value: 0.7902631937815355.\u001b[0m\n",
      "2026/02/22 23:28:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/22 23:28:59 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost_SMOTE_TFIDF_Trigrams at: https://dagshub.com/prasu202324/YTintel-extension.mlflow/#/experiments/5/runs/d4836b930e264b019fa86fe39bc72625\n",
      "üß™ View experiment at: https://dagshub.com/prasu202324/YTintel-extension.mlflow/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a06105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
